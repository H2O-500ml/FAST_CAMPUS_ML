{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 보충 자료"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01_linear_regression.ipynb의 주요 내용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "data = pd.read_csv('data/bikeshare.csv')\n",
    "\n",
    "# Year와 Month를 추출\n",
    "datetime = pd.DatetimeIndex(data['datetime'])\n",
    "data['year'] = datetime.year\n",
    "data['month'] = datetime.month\n",
    "data['hour'] = datetime.hour\n",
    "\n",
    "# \"count\" is a method, so it's best to name that column something else\n",
    "data.rename(columns={'count':'total'}, inplace=True)\n",
    "\n",
    "# Handling 'season' variable\n",
    "season_dummies = pd.get_dummies(data.season, prefix='season')\n",
    "season_dummies.drop(season_dummies.columns[0], axis=1, inplace=True)\n",
    "data = pd.concat([data, season_dummies], axis=1)\n",
    "\n",
    "# Add derivative variable \"daytime\"\n",
    "data['daytime'] = ((data.hour > 6) & (data.hour < 21)).astype(int)\n",
    "\n",
    "# Handling 'hour' variable\n",
    "hour_dummies = pd.get_dummies(data.hour, prefix='hour')\n",
    "hour_dummies.drop(hour_dummies.columns[0], axis=1, inplace=True)\n",
    "data = pd.concat([data, hour_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 선형회귀모델을 학습하는 함수를 조금 수정하였습니다.\n",
    "다음을 포함하는 dictionary를 출력하는 함수로 변경하였습니다.\n",
    "- 각 변수에 대응하는 계수들(coefficients)과 intercept\n",
    "- Train set에서의 RMSE, R^2\n",
    "- Test set에서의 RMSE, R^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that accepts a list of features and\n",
    "# returns coefficients, intercept, training RMSE/R^2 and testing RMSE/R^2\n",
    "def train_test_linreg(d, feature_cols):\n",
    "    X = d[feature_cols]\n",
    "    Y = d.total\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=123)\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, Y_train)\n",
    "    \n",
    "    # Make series using selected features and corresponding coefficients\n",
    "    formula = pd.Series(model.coef_, index = feature_cols)\n",
    "    \n",
    "    # Save intercept\n",
    "    intercept = model.intercept_\n",
    "    \n",
    "    # Calculate training RMSE and testing RMSE\n",
    "    Y_pred_train = model.predict(X_train)\n",
    "    Y_pred_test = model.predict(X_test)\n",
    "    rmse_train = np.sqrt(metrics.mean_squared_error(Y_train, Y_pred_train))\n",
    "    rmse_test = np.sqrt(metrics.mean_squared_error(Y_test, Y_pred_test))\n",
    "    \n",
    "    # Calculate training R-square and testing R-square\n",
    "    rsquared_train = model.score(X_train, Y_train)\n",
    "    rsquared_test = model.score(X_test, Y_test)\n",
    "    \n",
    "    # Make result dictionary\n",
    "    result={'formula':formula, 'intercept':intercept, 'rmse_train':rmse_train, 'rmse_test':rmse_test,\n",
    "           'rsquared_train':rsquared_train, 'rsquared_test':rsquared_test}\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hour에 대한 binary dummy variable만 이용하여 선형회귀모델을 학습\n",
    "hour_cols = list(data.columns[data.columns.str.startswith('hour_')])\n",
    "result = train_test_linreg(data, hour_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'formula': hour_1     -22.580917\n",
       " hour_2     -32.757474\n",
       " hour_3     -44.209704\n",
       " hour_4     -49.961957\n",
       " hour_5     -36.711049\n",
       " hour_6      16.801172\n",
       " hour_7     159.656510\n",
       " hour_8     309.943473\n",
       " hour_9     160.149618\n",
       " hour_10    121.193570\n",
       " hour_11    147.090587\n",
       " hour_12    202.425259\n",
       " hour_13    200.110370\n",
       " hour_14    195.261156\n",
       " hour_15    195.486156\n",
       " hour_16    266.890255\n",
       " hour_17    419.952457\n",
       " hour_18    379.068371\n",
       " hour_19    264.786324\n",
       " hour_20    173.622659\n",
       " hour_21    125.548656\n",
       " hour_22     77.631922\n",
       " hour_23     34.730308\n",
       " dtype: float64,\n",
       " 'intercept': 56.263843648208336,\n",
       " 'rmse_train': 124.92842235488433,\n",
       " 'rmse_test': 128.47511657303033,\n",
       " 'rsquared_train': 0.5263145338683541,\n",
       " 'rsquared_test': 0.4919246495057706}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check coefficients, intercept, training RMSE/R^2 and testing RMSE/R^2\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge regression & Lasso regression\n",
    "### 두 모델의 공통점\n",
    "- **Regularization**: 모델 계수가 커지는 것에 대한 penalty를 부여함으로써 모델의 overfitting(과적합)을 방지\n",
    "- 기본적인 multiple linear regression (다중선형회귀분석) 은 변수 간의 [다중공산성(multicollinearity)](https://ko.wikipedia.org/wiki/%EB%8B%A4%EC%A4%91%EA%B3%B5%EC%84%A0%EC%84%B1)에 의해 성능이 하락하는데, 이 두 회귀모델은 이에 대해 대처할 수 있는 모델\n",
    "- 모델의 parameter(모수)가 존재: 계수 크기에 대한 penalty를 얼마나 줄 것인가 (**alpha**)\n",
    "- alpha가 0이면 단순 다중선형회귀모델과 일치\n",
    "\n",
    "\n",
    "### Lasso regression의 강점\n",
    "- Lasso regression은 ridge regression과는 달리 특정 변수의 계수를 0으로 만들어줍니다. 특정 변수의 계수가 0이 아니라는 것은 **lasso regression 모델이 그 변수를 선택**했다고 볼 수 있습니다.\n",
    "- Lasso regression은 모든 변수가 선택되는 것이 아니라는 점에서 **sparse model** (희소모델)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "두 모델을 적용하기에 앞서 다음과 같은 데이터 전처리를 다시 실시하였습니다.\n",
    "- X에서 가능한 모든 변수를 사용하여, 모델의 성능이 어떻게 나오는지 파악\n",
    "- 제거한 변수: datetime (수치형 변수가 아니며, year/month/hour로 이미 분리됨),casual & registered (타겟변수인 'total'과 함께 움직이는 변수), total (타겟 변수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_ridge(data, alpha_value):\n",
    "    X = data.drop(['datetime','casual','registered','total', 'season', 'hour'], axis = 1)\n",
    "    Y = data.total\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=123)\n",
    "    model = Ridge(alpha = alpha_value)\n",
    "    model.fit(X_train, Y_train)\n",
    "    \n",
    "    # Make series using selected features and corresponding coefficients\n",
    "    formula = pd.Series(model.coef_, index = list(X.columns.values))\n",
    "    \n",
    "    # Save intercept\n",
    "    intercept = model.intercept_\n",
    "    \n",
    "    # Calculate training RMSE and testing RMSE\n",
    "    Y_pred_train = model.predict(X_train)\n",
    "    Y_pred_test = model.predict(X_test)\n",
    "    rmse_train = np.sqrt(metrics.mean_squared_error(Y_train, Y_pred_train))\n",
    "    rmse_test = np.sqrt(metrics.mean_squared_error(Y_test, Y_pred_test))\n",
    "    \n",
    "    # Calculate training R-square and testing R-square\n",
    "    rsquared_train = model.score(X_train, Y_train)\n",
    "    rsquared_test = model.score(X_test, Y_test)\n",
    "    \n",
    "    # Make result dictionary\n",
    "    result={'formula':formula, 'intercept':intercept, 'rmse_train':rmse_train, 'rmse_test':rmse_test,\n",
    "           'rsquared_train':rsquared_train, 'rsquared_test':rsquared_test}\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge regression 학습 및 테스트 (alpha = 0.1)\n",
    "result = train_test_ridge(data, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'formula': holiday        -0.241201\n",
       " workingday      3.557334\n",
       " weather       -24.250728\n",
       " temp            2.657642\n",
       " atemp           2.693038\n",
       " humidity       -0.731705\n",
       " windspeed      -0.539184\n",
       " year           86.444968\n",
       " month           8.290617\n",
       " season_2       20.127684\n",
       " season_3      -16.690652\n",
       " season_4       -7.824809\n",
       " daytime       191.240046\n",
       " hour_1        -23.346823\n",
       " hour_2        -30.521447\n",
       " hour_3        -43.572011\n",
       " hour_4        -46.730807\n",
       " hour_5        -26.958390\n",
       " hour_6         27.121898\n",
       " hour_7        -26.382880\n",
       " hour_8        123.076170\n",
       " hour_9        -34.180309\n",
       " hour_10       -83.987526\n",
       " hour_11       -62.543739\n",
       " hour_12       -16.971829\n",
       " hour_13       -23.317104\n",
       " hour_14       -36.655135\n",
       " hour_15       -33.326099\n",
       " hour_16        33.768118\n",
       " hour_17       190.191174\n",
       " hour_18       151.853058\n",
       " hour_19        47.584876\n",
       " hour_20       -37.868730\n",
       " hour_21       102.251093\n",
       " hour_22        64.681551\n",
       " hour_23        27.221663\n",
       " dtype: float64,\n",
       " 'intercept': -173899.69805504192,\n",
       " 'rmse_train': 100.4177999772268,\n",
       " 'rmse_test': 102.91507802232455,\n",
       " 'rsquared_train': 0.6939524175963656,\n",
       " 'rsquared_test': 0.6739771047536309}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_lasso(data, alpha_value):\n",
    "    X = data.drop(['datetime','casual','registered','total', 'season', 'hour'], axis = 1)\n",
    "    Y = data.total\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=123)\n",
    "    model = Lasso(alpha = alpha_value)\n",
    "    model.fit(X_train, Y_train)\n",
    "    \n",
    "    # Make series using selected features and corresponding coefficients\n",
    "    formula = pd.Series(model.coef_, index = list(X.columns.values))\n",
    "    \n",
    "    # Save intercept\n",
    "    intercept = model.intercept_\n",
    "    \n",
    "    # Calculate training RMSE and testing RMSE\n",
    "    Y_pred_train = model.predict(X_train)\n",
    "    Y_pred_test = model.predict(X_test)\n",
    "    rmse_train = np.sqrt(metrics.mean_squared_error(Y_train, Y_pred_train))\n",
    "    rmse_test = np.sqrt(metrics.mean_squared_error(Y_test, Y_pred_test))\n",
    "    \n",
    "    # Calculate training R-square and testing R-square\n",
    "    rsquared_train = model.score(X_train, Y_train)\n",
    "    rsquared_test = model.score(X_test, Y_test)\n",
    "    \n",
    "    # Make result dictionary\n",
    "    result={'formula':formula, 'intercept':intercept, 'rmse_train':rmse_train, 'rmse_test':rmse_test,\n",
    "           'rsquared_train':rsquared_train, 'rsquared_test':rsquared_test}\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso regression 학습 및 테스트 (alpha = 0.1)\n",
    "result = train_test_lasso(data, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'formula': holiday        -0.000000\n",
       " workingday      0.000000\n",
       " weather        -9.913521\n",
       " temp            1.266311\n",
       " atemp           4.476017\n",
       " humidity       -1.327402\n",
       " windspeed      -0.224684\n",
       " year           71.943534\n",
       " month           6.761166\n",
       " season_2        5.685929\n",
       " season_3       -1.415003\n",
       " season_4        0.000000\n",
       " daytime       157.830886\n",
       " hour_1         -0.000000\n",
       " hour_2         -0.000000\n",
       " hour_3         -0.000000\n",
       " hour_4         -0.000000\n",
       " hour_5         -0.000000\n",
       " hour_6          0.000000\n",
       " hour_7         -0.000000\n",
       " hour_8         76.457096\n",
       " hour_9         -0.000000\n",
       " hour_10        -0.000000\n",
       " hour_11        -0.000000\n",
       " hour_12        -0.000000\n",
       " hour_13        -0.000000\n",
       " hour_14        -0.000000\n",
       " hour_15        -0.000000\n",
       " hour_16         0.000000\n",
       " hour_17       130.447777\n",
       " hour_18        87.489301\n",
       " hour_19         0.000000\n",
       " hour_20        -0.000000\n",
       " hour_21        16.864350\n",
       " hour_22         0.000000\n",
       " hour_23         0.000000\n",
       " dtype: float64,\n",
       " 'intercept': -144704.9729606603,\n",
       " 'rmse_train': 111.28972771829721,\n",
       " 'rmse_test': 112.55517717437426,\n",
       " 'rsquared_train': 0.6240953411378848,\n",
       " 'rsquared_test': 0.6100391247553515}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파악할 부분\n",
    "- Ridge regression과 Lasso regression의 결과와 단순선형회귀모델의 결과를 비교해보세요.\n",
    "- 위의 Ridge regression과 Lasso regression에서 alpha값을 변형해가면서 결과가 달라지는지 살펴보세요."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
